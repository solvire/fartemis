# Fartemis Project Technical Checkpoint
## Project Context
We're developing a robust job hunting assistant focused on integrating job data from LinkedIn. Our current focus has been on building a complete pipeline that efficiently collects, processes, and stores job postings, with particular emphasis on handling company profiles and extracting salary information. This integration is crucial for providing high-quality job recommendations to users, especially for senior engineers seeking opportunities at early-stage companies.

## Current Progress Summary

### LinkedIn Integration System
- Implemented a streamlined FeedItem model for efficient raw data storage
- Created a specialized command for fetching LinkedIn job listings
- Developed a GeoID lookup system for enhanced geographical targeting
- Implemented a "firehose" approach to overcome LinkedIn's unreliable filtering

### Data Processing Pipeline
- Built LinkedInJobMapper for transforming raw data to structured Job records
- Created CompanyMapper for handling company profile matching and creation
- Developed an intelligent salary extraction system using regex and LLM
- Implemented command-line tools for processing job data with robust error handling

### Database and Model Structure
- Moved from file-based storage to database-centric approach
- Used JSON fields for flexible data storage while maintaining query capabilities
- Created efficient indexing for optimized retrieval
- Established relationship links between FeedItems, Jobs, and Company Profiles

## Technical Implementation Details
### FeedItem Model Structure
We significantly simplified our data storage approach with a streamlined FeedItem model:

```python
class FeedItem(BaseIntModel):
    """Represents a raw job posting from a feed source before processing."""
    
    guid = models.CharField(max_length=255, help_text="Unique ID from source")
    source = models.ForeignKey(
        FeedSource, 
        related_name='items',
        on_delete=models.CASCADE
    )
    raw_data = models.JSONField(default=dict, blank=True, help_text="Original data from source")
    is_processed = models.BooleanField(default=False, help_text="Whether this item has been processed into a Job")
    job = models.ForeignKey(
        'jobboards.Job',
        on_delete=models.SET_NULL,
        related_name='feed_sources',
        null=True,
        blank=True
    )
    
    class Meta:
        app_label = 'jobboards'
        verbose_name = _('Feed Item')
        verbose_name_plural = _('Feed Items')
        unique_together = ('source', 'guid')  # Ensure no duplicates
        indexes = [
            models.Index(fields=['is_processed']),
        ]
    
    def __str__(self):
        title = self.raw_data.get('title', self.guid) if isinstance(self.raw_data, dict) else self.guid
        return f"{title} ({self.source.name})"
```

### LinkedIn Fetch Command
We developed a robust command for fetching LinkedIn jobs and storing them as FeedItems:

```python
class Command(BaseCommand):
    help = 'Fetch jobs from LinkedIn and store them directly as feed items'

    def add_arguments(self, parser):
        parser.add_argument('--keywords', type=str, default='Python Engineer', 
                            help='Search keywords')
        parser.add_argument('--geo-id', type=str,
                            help='LinkedIn GeoID (obtained from linkedin_geoid_finder command)')
        parser.add_argument('--location', type=str,
                            help='Location for job')
        parser.add_argument('--limit', type=int, default=25, 
                            help='Number of results to fetch')
        parser.add_argument('--levels', type=str, default='senior,manager,director', 
                            help='Experience levels (comma separated)')
        parser.add_argument('--verbose', action='store_true', 
                            help='Display full job descriptions')

    def handle(self, *args, **options):
        # Extract options and initialize API client
        # ...
        
        # Search for jobs and process results
        jobs = self._fetch_jobs(api, search_params)
        self._process_job_results(api, jobs, feed_source, keywords, location, geo_id, levels)
```

### Job Processing Command
We created a command to process FeedItems into structured Job objects:

```python
class Command(BaseCommand):
    help = 'Process FeedItems into Job objects with company profiles'

    def add_arguments(self, parser):
        parser.add_argument('--id', type=int, help='Process a specific FeedItem by ID')
        parser.add_argument('--batch-size', type=int, default=50,
                            help='Number of FeedItems to process in one batch (default: 50)')
        parser.add_argument('--source', type=str, help='Process only FeedItems from a specific source')
        parser.add_argument('--user-id', type=int, help='Assign jobs to a specific user by ID')
        parser.add_argument('--username', type=str, help='Assign jobs to a specific user by username')
        # Additional arguments...

    def _process_item(self, item, verbose, skip_company, user=None):
        """Process a single FeedItem and return the created Job (if successful)."""
        with transaction.atomic():
            # Determine appropriate mapper
            if item.source.name == 'linkedin':
                mapper = LinkedInJobMapper()
            else:
                # No mapper available
                return None
                
            # Extract data components
            job_summary = item.raw_data.get('job_summary', {})
            job_details = item.raw_data.get('job_details', {})
            
            # Map to Job object with user
            job = mapper.map_job(job_summary, job_details, user)
            
            if job:
                # Process company information
                if not skip_company and self.company_mapper:
                    company_profile = self.company_mapper.get_or_create_company(item.raw_data)
                    if company_profile:
                        job.company_profile = company_profile
                        job.save()
                
                # Link job to feed item
                item.job = job
                item.is_processed = True
                item.save()
                
                return job
            return None
```

### CompanyMapper Implementation
We implemented a robust mapper for handling company data:

```python
class CompanyMapper:
    """
    Maps LinkedIn company data to CompanyProfile objects.
    Handles finding existing companies or creating new ones.
    """
    
    def __init__(self):
        self.linkedin_api = None
    
    def get_or_create_company(self, job_data: Dict[str, Any]) -> Optional[CompanyProfile]:
        """
        Extract company info from job data and either find or create a company.
        """
        try:
            # Extract basic company info
            company_info = self._extract_company_info_from_job(job_data)
            
            if not company_info or not company_info.get('name'):
                logger.warning("Could not extract company name from job data")
                return None
            
            # Try to find existing company
            existing_company = self._find_existing_company(company_info)
            
            if existing_company:
                return existing_company
            
            # If LinkedIn ID is available, try to get full company data
            linkedin_id = company_info.get('linkedin_id')
            if linkedin_id and self.initialize_linkedin_api():
                company_data = self.linkedin_api.get_company(linkedin_id)
                if company_data:
                    return self._create_company_from_linkedin_data(company_data)
            
            # Fallback to creating company with minimal info
            return self._create_company_from_job_data(company_info)
            
        except Exception as e:
            logger.error(f"Error in get_or_create_company: {str(e)}")
            return None
            
    def _find_best_fuzzy_match(self, company_name: str) -> Tuple[Optional[CompanyProfile], float]:
        """Find the best fuzzy match for a company name."""
        if not company_name:
            return None, 0.0
            
        best_match = None
        best_score = 0.0
        
        normalized_name = self._normalize_company_name(company_name)
        
        for company in CompanyProfile.objects.all():
            normalized_company_name = self._normalize_company_name(company.name)
            
            # Calculate similarity ratio
            similarity = SequenceMatcher(None, normalized_name, normalized_company_name).ratio()
            
            if similarity > best_score:
                best_score = similarity
                best_match = company
        
        return best_match, best_score
```

### Salary Extraction Implementation
We developed a sophisticated system for extracting salary information:

```python
def extract_salary_info(description: str, user=None) -> Dict[str, Any]:
    """
    Extract salary information from a job description using pattern matching
    and LLM-based extraction.
    """
    # Default return structure
    result = {
        'has_salary': False,
        'salary_min': None,
        'salary_max': None, 
        'salary_currency': None,
        'salary_period': None,
        'confidence': 0.0,
        'raw_match': None
    }
    
    if not description:
        return result
    
    # First try pattern matching for common salary formats
    pattern_result = _extract_salary_with_patterns(description)
    
    if pattern_result['has_salary'] and pattern_result['confidence'] > 0.8:
        # High confidence match with regex, return without using LLM
        return pattern_result
    
    # If no clear match or low confidence, use LLM for extraction
    try:
        llm_result = _extract_salary_with_llm(description, user)
        
        # Use result with higher confidence
        if (pattern_result['confidence'] < llm_result['confidence'] or 
            not pattern_result['has_salary']):
            return llm_result
        
        # Otherwise use pattern result
        return pattern_result
        
    except Exception as e:
        logger.error(f"Error extracting salary with LLM: {str(e)}")
        # Fall back to pattern matching result if LLM fails
        return pattern_result
```

## Data Structures and API Responses
### LinkedIn API Response Structure
LinkedIn's API returns job data in multiple components:

**Job Summary (from search results)**:
```python
{
    'trackingUrn': 'urn:li:jobPosting:4182694556',
    'repostedJob': False,
    'title': 'Software Engineer III, AI/ML, YouTube',
    '$recipeTypes': ['com.linkedin.deco.recipe.anonymous.Anon1578943416'],
    'posterId': '29326500',
    '$type': 'com.linkedin.voyager.dash.jobs.JobPosting',
    'contentSource': 'JOBS_PREMIUM_OFFLINE',
    'entityUrn': 'urn:li:fsd_jobPosting:4182694556'
}
```

**Job Details (from individual job pages)**:
```python
{
    'dashEntityUrn': 'urn:li:fsd_jobPosting:4182694556',
    'companyDetails': {
        'com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany': {
            'company': 'urn:li:fs_normalized_company:76637056',
            'companyResolutionResult': {
                'name': 'Evolution Recruitment Solutions, USA',
                'url': 'https://www.linkedin.com/company/evolution-recruitment-solutions-usa',
                'entityUrn': 'urn:li:fs_normalized_company:76637056'
            }
        }
    },
    'jobState': 'LISTED',
    'description': 'Job description text...',
    'title': 'Software Engineer III, AI/ML, YouTube',
    'workRemoteAllowed': False,
    'formattedLocation': 'Mountain View, CA',
    'listedAt': 1741986856000,
    # Additional fields...
}
```

**Company Data Response**:
```python
{
    'staffingCompany': False, 
    'companyIndustries': [
        {'localizedName': 'Staffing and Recruiting', 'entityUrn': 'urn:li:fs_industry:104'}
    ], 
    'staffCount': 16, 
    'staffCountRange': {'start': 11, 'end': 50}, 
    'name': 'Segrera Associates', 
    'tagline': 'Hire Smart. Grow Your Business ', 
    'description': 'Segrera Associates is a professional recruiting and staffing firm...',
    'entityUrn': 'urn:li:fs_normalized_company:2388424', 
    'headquarter': {
        'country': 'US', 
        'geographicArea': 'FL', 
        'city': 'Miami', 
        'postalCode': '33126', 
        'line1': '1000 NW 57th Court, Suite 950'
    }, 
    'foundedOn': {'year': 2011},
    'companyType': {'localizedName': 'Privately Held', 'code': 'PRIVATELY_HELD'}
}
```

### Combined FeedItem Raw Data Structure
We store the combined data in the FeedItem.raw_data field:
```python
{
    'job_summary': {
        # Original job summary data from search results
    },
    'job_details': {
        # Original job details data from job page
    },
    'skills_data': {
        # Original skills data from LinkedIn API
    },
    'extracted_skills': [
        # List of extracted skill names
        'Python', 'Machine Learning', 'TensorFlow'
    ],
    'query_metadata': {
        'keywords': 'Python Engineer',
        'location': 'San Francisco',
        'geo_id': '12345',
        'timestamp': '20250320_123045',
        'levels': ['senior', 'manager'],
        'search_id': '20250320_123045'
    }
}
```

## Integration Points
### LinkedIn API to FeedItem
We fetch and store job data directly from LinkedIn to our database:
```python
def _process_job(self, api, job, feed_source, search_timestamp, query_metadata):
    try:
        # Extract job ID
        job_id = job.get('jobId', job.get('entityUrn', '').split(':')[-1])
        
        if not job_id:
            self.stderr.write(f'Could not extract job ID from job')
            return None
        
        # Format the GUID to include the source
        guid = f"linkedin_{job_id}"
        
        # Check for existing item
        existing_item = FeedItem.objects.filter(
            source=feed_source,
            guid=guid
        ).first()
        
        if existing_item:
            self.stdout.write(f'Job {job_id} already exists in database, skipping...')
            return None
        
        # Get detailed job information
        details = api.get_job(job_id)
        
        # Try to get skills
        skills_data = None
        skills = []
        try:
            skills_data = api.get_job_skills(job_id)
            if skills_data and 'skillMatchStatuses' in skills_data:
                for skill_data in skills_data.get('skillMatchStatuses', []):
                    skill_name = skill_data.get('skill', {}).get('name', '')
                    if skill_name:
                        skills.append(skill_name)
        except Exception as e:
            self.stderr.write(f'Error fetching skills for job {job_id}: {str(e)}')
        
        # Create combined data object
        combined_data = {
            'job_summary': job,
            'job_details': details,
            'skills_data': skills_data,
            'extracted_skills': skills,
            'query_metadata': query_metadata
        }
        
        # Create FeedItem
        feed_item = FeedItem.objects.create(
            guid=guid,
            source=feed_source,
            raw_data=combined_data,
            is_processed=False
        )
        
        return feed_item
        
    except Exception as e:
        self.stderr.write(f'Error processing job: {str(e)}')
        return None
```

### FeedItem to Job with Company Profile
The integration between feed items, jobs, and company profiles:
```python
def _process_item(self, item, verbose, skip_company, user=None):
    with transaction.atomic():
        try:
            # Get appropriate mapper
            mapper = LinkedInJobMapper()
            
            # Extract data components
            job_summary = item.raw_data.get('job_summary', {})
            job_details = item.raw_data.get('job_details', {})
            
            # Map to Job object
            job = mapper.map_job(job_summary, job_details, user)
            
            if job:
                # Process company information if not skipped
                if not skip_company and self.company_mapper:
                    company_profile = self.company_mapper.get_or_create_company(item.raw_data)
                    if company_profile:
                        # Link the company profile to the job
                        job.company_profile = company_profile
                        job.save()
                
                # Link the job back to the feed item
                item.job = job
                item.is_processed = True
                item.save()
                
                return job
            return None
        except Exception as e:
            logger.error(f"Error processing item: {str(e)}")
            raise
```

## Key Decisions and Rationale

### Decision: Use a simplified FeedItem model focused only on raw data storage

**Context**: Initially, we had a more complex FeedItem model with redundant fields.
**Options Considered**:
- **Option 1**: Keep detailed fields in both FeedItem and Job models - Redundant, harder to maintain
- **Option 2**: Use FeedItem only for temporary storage before creating Job objects - Simple but limited
- **Option 3**: Use FeedItem with minimal fields focused on storing raw data - Efficient, flexible

**Chosen Approach**: Option 3 - Simplified FeedItem model
**Rationale**: This approach keeps the raw data intact for future reference while avoiding redundancy. It also makes the feed system more adaptable to different data sources.

### Decision: Use database-centric storage rather than files

**Context**: Initially considered storing LinkedIn response data in timestamped files.
**Options Considered**:
- **Option 1**: File-based storage with timestamps - Traditional ETL approach
- **Option 2**: Database-centric storage in JSON fields - Integrated with application

**Chosen Approach**: Option 2 - Database-centric storage
**Rationale**: Eliminates file I/O overhead, makes data immediately available to the application, and simplifies deployment by removing file system dependencies.

### Decision: Implement company profile matching using fuzzy text comparison

**Context**: Company names often vary slightly across different job listings.
**Options Considered**:
- **Option 1**: Exact name matching only - Fast but misses variations
- **Option 2**: Normalized name matching - Better but still limited
- **Option 3**: Fuzzy matching with similarity threshold - Most flexible but slower

**Chosen Approach**: A tiered approach combining all three methods
**Rationale**: Provides the best balance of accuracy and performance by trying fast methods first before falling back to more sophisticated matching.

## Challenges and Solutions

### Challenge: LinkedIn API's unreliable filtering

**Problem**: Despite providing parameters for location, experience level, etc., LinkedIn's API often returns results that don't match these criteria.
**Solution**: Implemented a "firehose" approach - collect broadly and filter locally.
**Code Example**:
```python
# Instead of relying on LinkedIn's filters, we fetch more data and filter ourselves
def _process_job_results(self, api, jobs, feed_source, keywords, location, geo_id, levels):
    search_timestamp = timezone.now().strftime('%Y%m%d_%H%M%S')
    jobs_found = len(jobs) if jobs else 0
    jobs_processed = 0
    
    # First, collect all the data
    for job in jobs:
        # Store in FeedItem
        # ...
        
    # Later, in the mapper, we apply our own filtering
    def filter_job_by_criteria(self, job_details, criteria):
        """Apply our own filtering logic to job details."""
        # Location filtering
        if criteria.get('location') and job_details.get('formattedLocation'):
            if not self._location_matches(job_details['formattedLocation'], criteria['location']):
                return False
                
        # Level filtering
        # ... additional filtering logic
        
        return True
```

### Challenge: Handling various LinkedIn data structures

**Problem**: LinkedIn's API returns different data structures for company information.
**Solution**: Implemented a robust extraction method that handles multiple data formats.
**Code Example**:
```python
def _extract_company_info_from_job(self, job_data: Dict[str, Any]) -> Dict[str, Any]:
    company_info = {
        'name': None,
        'linkedin_id': None,
        'website': None,
        'headquarters_city': None,
        'headquarters_country': None
    }
    
    # Extract from job_details if available
    job_details = job_data.get('job_details', {})
    
    if job_details and 'companyDetails' in job_details:
        company_details = job_details['companyDetails']
        
        # Check if the LinkedIn structure uses the WebCompactJobPostingCompany recipe
        if 'com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany' in company_details:
            web_compact = company_details['com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany']
            
            # Extract LinkedIn ID from company URN
            if 'company' in web_compact:
                company_urn = web_compact.get('company', '')
                if company_urn:
                    company_info['linkedin_id'] = company_urn.split(':')[-1]
            
            # Extract company info from companyResolutionResult
            if 'companyResolutionResult' in web_compact:
                resolution = web_compact['companyResolutionResult']
                company_info['name'] = resolution.get('name')
                company_info['website'] = resolution.get('url')
        
        # Traditional structure checks (fallback)
        else:
            company_info['name'] = company_details.get('name')
            # Extract other fields...
            
    return company_info
```

### Challenge: Extracting salary information from unstructured text

**Problem**: Salary information appears in various formats within job descriptions.
**Solution**: Implemented a hybrid approach using both regex patterns and LLM processing.
**Code Example**:
```python
def _extract_salary_with_patterns(description: str) -> Dict[str, Any]:
    """Extract salary information using regex pattern matching."""
    result = {
        'has_salary': False,
        'salary_min': None,
        'salary_max': None, 
        'salary_currency': None,
        'salary_period': None,
        'confidence': 0.0,
        'raw_match': None
    }
    
    # Explicit salary pattern for labeled ranges
    explicit_salary_pattern = r'(?:salary|pay|compensation)\s+range:?\s+(?P<currency>[A-Z]{3}|\$|€|£|¥|₹|A\$|C\$|CHF|NZ\$)?\s*(?P<min>[\d,.]+[k]?)\s*(?:-|to|–)\s*(?:(?P<currency2>[A-Z]{3}|\$|€|£|¥|₹|A\$|C\$|CHF|NZ\$)?\s*)?(?P<max>[\d,.]+[k]?)'
    
    # Regular salary range pattern
    salary_range_pattern = r'(?P<currency>[A-Z]{3}|\$|€|£|¥|₹|A\$|C\$|CHF|NZ\$)\s*(?P<min>[\d,.]+[k]?)\s*(?:-|to|–)\s*(?P<currency2>[A-Z]{3}|\$|€|£|¥|₹|A\$|C\$|CHF|NZ\$)?\s*(?P<max>[\d,.]+[k]?)'
    
    # Additional patterns and processing...
    
    return result
```

## Next Steps

### Implement Advanced Filtering Pipeline

- Develop NLP-based extraction of job attributes
- Build scoring system for job quality and relevance
- Create classifiers for identifying early-stage companies

### Enhance Company Profile Enrichment

- Develop algorithms to match jobs to existing company profiles
- Implement creation of new company profiles for unknown companies
- Build company information enrichment from other sources

### Add Additional Job Sources

- Implement Hacker News "Who is Hiring" feed client
- Add support for remote job board feeds
- Build Reddit job board integration

### Build Recommendation Engine

- Develop personalized job matching algorithms
- Create relevance scoring system
- Implement user preference learning

## References and Resources

### Internal References:

- FeedSource model: fartemis.jobboards.models.FeedSource
- FeedItem model: fartemis.jobboards.models.FeedItem
- Job model: fartemis.jobboards.models.Job
- CompanyProfile model: fartemis.companies.models.CompanyProfile
- LinkedIn fetch command: fartemis.jobboards.management.commands.fetch_linkedin_jobs
- Process feed items command: fartemis.jobboards.management.commands.process_feed_items
- Company operations command: fartemis.companies.management.commands.company_operations

### External References:

- LinkedIn API SDK: https://linkedin-api.readthedocs.io
- Anthropic Claude API: https://docs.anthropic.com/claude/reference/getting-started-with-the-api
- Django Documentation: https://docs.djangoproject.com/en/5.0/

This checkpoint provides a comprehensive overview of our LinkedIn integration progress, with detailed code examples and architectural decisions. It should serve as a solid foundation for continuing the development in the next session.