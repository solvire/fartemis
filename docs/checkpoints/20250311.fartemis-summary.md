# Fartemis Project Checkpoint - 2025-03-11

## Project Context
Fartemis is an AI-powered job hunting assistant built on Django. We're developing a system to circumvent the limitations of LinkedIn and Indeed APIs by creating a multi-source feed aggregation system.

## Current Architecture

### Core Components Developed Today:

1. **Feed Client System**
   - BaseFeedClient abstract class
   - Concrete implementations for different sources (RSS, Hacker News, Reddit)
   - Factory pattern for client creation

2. **Feed Storage Models**
   - FeedSource: Configuration for feed sources
   - FeedItem: Standardized job postings
   - FeedFetchLog: Tracking fetch operations

3. **Controllers**
   - FeedController: Managing feed operations
   - JobFactory: Converting feed items to jobs

4. **LLM Integration**
   - Using Anthropic's Claude for job data enrichment
   - Extracting structured information from job descriptions

## Key Code Examples

### Feed Client Factory
```python
class FeedClientFactory:
    """Factory for creating feed clients."""
    
    @staticmethod
    def create(source_type: str, name: str, url: str, **kwargs) -> Optional[BaseFeedClient]:
        """
        Create a feed client based on source type.
        
        Args:
            source_type: Type of feed source ('rss', 'hackernews', 'reddit', etc.)
            name: Name of the feed source
            url: URL of the feed source
            **kwargs: Additional configuration parameters
            
        Returns:
            BaseFeedClient instance or None if source_type is not supported
        """
        try:
            if source_type == 'rss':
                return RSSFeedClient(name, url)
                
            elif source_type == 'hackernews':
                thread_id = kwargs.get('thread_id')
                return HackerNewsWhoIsHiringClient(name, thread_id)
                
            elif source_type == 'reddit':
                subreddit = kwargs.get('subreddit', 'forhire')
                return RedditJobBoardClient(name, subreddit)
                
            else:
                logger.warning(f"Unsupported feed source type: {source_type}")
                return None
                
        except Exception as e:
            logger.error(f"Error creating feed client for {name} ({source_type}): {e}")
            return None
```

### Job Factory
```python
class JobFactory:
    """Factory for creating job instances from different sources."""
    
    @staticmethod
    def create_from_feed_item(feed_item: FeedItem, search_query=None) -> Optional[Job]:
        """
        Create a job instance from a feed item.
        
        Args:
            feed_item: The feed item to convert
            search_query: Optional job search query to associate with
            
        Returns:
            Job instance or None if creation fails
        """
        try:
            with transaction.atomic():
                # Create a generic search query if needed
                if not search_query:
                    search_query, _ = JobSearchQuery.objects.get_or_create(
                        query="feed_import",
                        defaults={'user': None}
                    )
                
                # Create the job
                job = Job.objects.create(
                    title=feed_item.title,
                    description=feed_item.description,
                    company_name=feed_item.company_name or "Unknown",
                    url=feed_item.url,
                    source="feed",
                    company_profile=feed_item.company_profile,
                    posted_date=feed_item.posted_date,
                    status="new"
                )
                
                # Link to search query
                job.search_queries.add(search_query)
                
                # Add technologies from feed item
                if feed_item.technologies.exists():
                    job.required_skills.add(*feed_item.technologies.all())
                
                # Link back to feed item
                feed_item.job = job
                feed_item.save(update_fields=['job'])
                
                return job
                
        except Exception as e:
            logger.error(f"Error creating job from feed item {feed_item.id}: {e}")
            return None
```

### Feed Models
```python
class FeedSource(BaseIntModel):
    """Feed source configuration."""
    
    name = models.CharField(max_length=100, unique=True)
    url = models.URLField(max_length=500)
    source_type = models.CharField(
        max_length=50,
        choices=[
            ('rss', 'RSS/Atom Feed'),
            ('hackernews', 'Hacker News Who Is Hiring'),
            ('reddit', 'Reddit'),
            ('custom', 'Custom Source'),
        ],
        default='rss'
    )
    is_active = models.BooleanField(default=True)
    last_fetched = models.DateTimeField(null=True, blank=True)
    fetch_interval_minutes = models.IntegerField(default=60)  # How often to fetch
    config = models.JSONField(default=dict, blank=True)  # Additional config params
```

```python
class FeedItem(BaseIntModel):
    """Represents a job posting from a feed."""
    
    title = models.CharField(max_length=255)
    description = models.TextField()
    url = models.URLField(max_length=500)
    company_name = models.CharField(max_length=255, null=True, blank=True)
    location = models.CharField(max_length=255, null=True, blank=True)
    posted_date = models.DateTimeField(null=True, blank=True)
    
    # Feed source relations
    source = models.ForeignKey(
        FeedSource, 
        related_name='items',
        on_delete=models.CASCADE
    )
    
    # Reference to original item
    guid = models.CharField(max_length=255)  # Unique ID from source
    raw_data = models.JSONField(default=dict, blank=True)  # Original data
    
    # Company profile relation (if matched)
    company_profile = models.ForeignKey(
        'fartemis.companies.CompanyProfile',
        on_delete=models.SET_NULL,
        related_name='feed_items',
        null=True,
        blank=True
    )
```

### FeedController Snippet
```python
def use_llm_for_enrichment(self, item: FeedItem) -> Dict[str, Any]:
    """Use LLM to extract structured information from job posting."""
    from fartemis.llms.clients import LLMClientFactory
    from fartemis.llms.constants import LLMProvider
    
    if not self.llm_client:
        self.llm_client = LLMClientFactory.create(LLMProvider.ANTHROPIC)
        
    # Prepare prompt
    prompt = f"""
    You are a job posting analyzer. Extract the following information from this job posting:
    
    JOB TITLE: {item.title}
    JOB DESCRIPTION: {item.description[:2000]}...  # Truncate for token limits
    
    Please extract the following information in JSON format:
    1. company_name: The name of the company hiring
    2. location: Where the job is located (remote, office location, etc.)
    3. job_type: Full-time, part-time, contract, etc.
    4. experience_level: Junior, mid-level, senior, etc.
    5. technologies: List of specific technologies, languages, frameworks mentioned
    6. salary_range: If mentioned, the salary range
    7. key_responsibilities: List of main job responsibilities
    8. required_skills: List of explicitly required skills
    9. preferred_skills: List of preferred but not required skills
    10. education_requirements: Any specific education requirements
    11. benefits: Any mentioned benefits or perks
    
    Return only valid JSON without any explanations.
    """
```

## Existing Anthropic Integration

Current implementation uses a more sophisticated client that supports:
- `complete` method (single prompt)
- `chat` method (conversation)
- System message handling
- Function calling via tools API
- Error handling with logging

```python
class AnthropicClient(BaseLLMClient):
    """
    Client for Anthropic's Claude models
    """
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.client = anthropic.Anthropic(api_key=self.api_key)
        
    def complete(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        Generate text completion using the Messages API
        """
        params = self.default_params.copy()
        params.update(kwargs)
        
        try:
            # Convert the single prompt to a messages format
            messages = [{"role": "user", "content": prompt}]
            
            # Ensure max_tokens is set
            if "max_tokens" not in params:
                params["max_tokens"] = 1000  # Default value
            
            response = self.client.messages.create(
                model=self.model,
                messages=messages,
                **params
            )
            
            # Extract the text from the response
            text = ""
            if response.content and len(response.content) > 0:
                if hasattr(response.content[0], 'text'):
                    text = response.content[0].text
                
            return {
                'text': text,
                'model': response.model,
                'raw_response': response
            }
        except Exception as e:
            logger.error(f"Error in Anthropic completion: {e}")
            raise
```

## Current LLM Factory

```python
@staticmethod
def create(provider: str, api_key: str, model: str = None, **kwargs) -> BaseLLMClient:
    """
    Create an LLM client for the specified provider
    
    Args:
        provider (str): Provider name from LLMProvider constants
        api_key (str): API key for the provider
        model (str, optional): Model name to use
        **kwargs: Additional parameters for the client
        
    Returns:
        BaseLLMClient: An initialized LLM client
    """
    if provider == LLMProvider.ANTHROPIC:
        model = model or ModelName.CLAUDE_3_SONNET
        return AnthropicClient(api_key=api_key, model=model, **kwargs)
    else:
        raise ValueError(f"Unsupported provider: {provider}")
```

## Next Steps

1. Update the feed controller LLM integration to properly use the existing Anthropic client:
   - Replace `generate_text` with `complete` or `chat`
   - Consider using `function_call` for structured data extraction

2. Implement additional feed sources:
   - Company career page monitors
   - More tech-focused job boards

3. Improve job matching:
   - Better technology extraction
   - Enhanced relevance scoring

4. Create a monitoring interface:
   - Track feed performance
   - Monitor new job discovery rates

## Project Structure

The feed system integrates with the existing Fartemis architecture:

```
fartemis/
├── core/
├── inherits/
├── companies/
├── jobboards/
│   ├── feed_clients.py        # Feed client implementations
│   ├── feed_factories.py      # Factory for feed clients
│   ├── feed_models.py         # Feed storage models
│   ├── feed_controller.py     # Business logic for feeds
│   ├── job_factories.py       # Factory for job creation
│   └── management/commands/   # Django commands for feeds
└── llms/
    ├── clients.py             # LLM clients (AnthropicClient)
    └── constants.py           # LLMProvider constants
```
